{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternating Minimization on Real Ranking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-65Kyq2Kv8R"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from helpers.helpers_pmf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the mean and standard deviations for the distributions\n",
    "mu = 0.0\n",
    "sigma_u = 1.0\n",
    "sigma_v = 1.0\n",
    "sigma = 0.2\n",
    "\n",
    "# Create an empty dictionary to store the parameters\n",
    "parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_hash</th>\n",
       "      <th>0071.jpg</th>\n",
       "      <th>0351.jpg</th>\n",
       "      <th>0428.jpg</th>\n",
       "      <th>0546.jpg</th>\n",
       "      <th>0001.jpg</th>\n",
       "      <th>0290.jpg</th>\n",
       "      <th>0527.jpg</th>\n",
       "      <th>0054.jpg</th>\n",
       "      <th>0652.jpg</th>\n",
       "      <th>...</th>\n",
       "      <th>0636.jpg</th>\n",
       "      <th>0409.jpg</th>\n",
       "      <th>0315.jpg</th>\n",
       "      <th>0741.jpg</th>\n",
       "      <th>0356.jpg</th>\n",
       "      <th>0650.jpg</th>\n",
       "      <th>0535.jpg</th>\n",
       "      <th>0382.jpg</th>\n",
       "      <th>0611.jpg</th>\n",
       "      <th>0128.jpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2u7T5g3WNhXLNt8eXLm7iYrvR872</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3mHQgTNdhoXXOWEsJmHvbBuOxSb2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4jQ4QWrm9SOsFMLIAajSZ5Usva82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5HBSsBrc7LSwIQyRgTqY7Zf641f2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69AHmihCRKbJbXXM9GQ4FT7NSU32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user_hash  0071.jpg  0351.jpg  0428.jpg  0546.jpg  \\\n",
       "0  2u7T5g3WNhXLNt8eXLm7iYrvR872       4.0       5.0       5.0       3.0   \n",
       "1  3mHQgTNdhoXXOWEsJmHvbBuOxSb2       1.0       0.0       0.0       1.0   \n",
       "2  4jQ4QWrm9SOsFMLIAajSZ5Usva82       0.0       1.0       0.0       0.0   \n",
       "3  5HBSsBrc7LSwIQyRgTqY7Zf641f2       1.0       1.0       0.0       1.0   \n",
       "4  69AHmihCRKbJbXXM9GQ4FT7NSU32       5.0       4.0       2.0       5.0   \n",
       "\n",
       "   0001.jpg  0290.jpg  0527.jpg  0054.jpg  0652.jpg  ...  0636.jpg  0409.jpg  \\\n",
       "0       1.0       1.0       1.0       1.0       1.0  ...       0.0       0.0   \n",
       "1       1.0       0.0       0.0       0.0       0.0  ...       0.0       0.0   \n",
       "2       0.0       0.0       0.0       0.0       0.0  ...       0.0       0.0   \n",
       "3       1.0       0.0       0.0       0.0       0.0  ...       0.0       0.0   \n",
       "4       1.0       1.0       1.0       1.0       1.0  ...       0.0       0.0   \n",
       "\n",
       "   0315.jpg  0741.jpg  0356.jpg  0650.jpg  0535.jpg  0382.jpg  0611.jpg  \\\n",
       "0       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   0128.jpg  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "\n",
       "[5 rows x 223 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_0_df = pd.read_csv('data/group_0.csv')\n",
    "group_1_df = pd.read_csv('data/group_1.csv')\n",
    "group_2_df = pd.read_csv('data/group_2.csv')\n",
    "group_3_df = pd.read_csv('data/group_3.csv')\n",
    "group_4_df = pd.read_csv('data/group_4.csv')\n",
    "ratings_df = pd.read_csv('data/ratings_per_user.csv')\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(ratings_df):\n",
    "    # Set the user_hash column as the index of the DataFrame\n",
    "    ratings_matrix_df = ratings_df.set_index('user_hash')\n",
    "\n",
    "    # Convert the DataFrame into a numpy array\n",
    "    ratings_matrix = ratings_matrix_df.values\n",
    "\n",
    "    # Get the number of users and items\n",
    "    n_users = ratings_matrix.shape[0]\n",
    "    n_items = ratings_matrix.shape[1]\n",
    "\n",
    "    return ratings_matrix, n_users, n_items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2C8nnfseBTOM"
   },
   "source": [
    "We will now initialise our parameters. First the $V$ matrix can be initialised randomly using the following distribution:\n",
    "\n",
    "\\begin{equation}\n",
    "\\large\n",
    "V \\sim \\mathcal N\\left(0, \\frac {1} {\\lambda_V}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "Let's remember that:\n",
    "\n",
    "\\begin{equation}\n",
    "\\large\n",
    "U \\in \\mathbb R^{D\\times N}, \\qquad V \\in \\mathbb R^{D\\times M}\n",
    "\\end{equation}\n",
    "\n",
    "Where $N$ is __n_users__, $M$ is __n_movies__ and $D$ is __n_dims__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HaM_fnR0Nd_i"
   },
   "outputs": [],
   "source": [
    "def init_params_real_data(sigma_U, sigma_V, mu, sigma, d_dims, n_users, n_movies, ratings_matrix):    \n",
    "    # Initialize U and V with random values\n",
    "    U_init = np.random.normal(mu, sigma_U, (d_dims, n_users))\n",
    "    V_init = np.random.normal(mu, sigma_V, (d_dims, n_movies))    \n",
    "    \n",
    "    # Set the ratings matrix, U, V, and lambda values in the parameters dictionary\n",
    "    parameters['R'] = ratings_matrix\n",
    "    parameters['U_result'] = U_init\n",
    "    parameters['V_result'] = V_init\n",
    "    parameters['lambda_U'] = sigma**2/sigma_U**2\n",
    "    parameters['lambda_V'] = sigma**2/sigma_V**2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create __ratings__ dataframe and append rating matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_real_data_df(n_users, n_movies):   \n",
    "    \n",
    "    df = pd.DataFrame(columns=['userID', 'movieID'])\n",
    "    df['userID'] = np.repeat(np.arange(1, n_users+1, 1), n_movies)\n",
    "    df['movieID'] = np.tile(np.arange(1, n_movies+1, 1), n_users)     \n",
    "    R = parameters['R']\n",
    "    df['rating'] = R.reshape(n_users*n_movies)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Split__ the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, train_size=0.75):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Sample a fraction of the DataFrame for the training set\n",
    "    train_set = df_copy.sample(frac=train_size, random_state=0)\n",
    "    \n",
    "    # Remove the samples in the training set from the copy to create the testing set\n",
    "    test_set = df_copy.drop(train_set.index)\n",
    "    \n",
    "    return train_set, test_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ntiPL_EnCLe-"
   },
   "source": [
    "Let's now implement the function that updates U and V. The elements of both matrices can be updated using the following expressions:\n",
    "\n",
    "\\begin{equation}\n",
    "\\large\n",
    "U_i=\\left[\\left(V_jV_j^T\\right)_{j\\in\\Omega_{U_i}}+\\lambda_UI\\right]^{-1}\\left(R_{ij}V_j^T\\right)_{j\\in\\Omega_{U_i}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\large\n",
    "V_j=\\left[\\left(U_iU_i^T\\right)_{i\\in\\Omega_{V_j}}+\\lambda_VI\\right]^{-1}\\left(R_{ij}U_i^T\\right)_{i\\in\\Omega_{V_j}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DjKB4TzFkoJx"
   },
   "outputs": [],
   "source": [
    "def update_parameters(n_users, n_movies, d_dims):\n",
    "    U = parameters['U_result']\n",
    "    V = parameters['V_result']\n",
    "    R = parameters['R']\n",
    "    lambda_U = parameters['lambda_U']\n",
    "    lambda_V = parameters['lambda_V']\n",
    "\n",
    "    # Update U for each user\n",
    "    for i in range(n_users):\n",
    "        # Select the items for which the user has provided ratings\n",
    "        V_j = V[:, R[i, :] > 0]\n",
    "        \n",
    "        # Compute the updated U for the user\n",
    "        U[:, i] = np.dot(np.linalg.inv(np.dot(V_j, V_j.T) + lambda_U * np.identity(d_dims)),\n",
    "                         np.dot(R[i, R[i, :] > 0], V_j.T))\n",
    "        \n",
    "    # Update V for each movie\n",
    "    for j in range(n_movies):\n",
    "        # Select the users who have rated the movie\n",
    "        U_i = U[:, R[:, j] > 0]\n",
    "        \n",
    "        # Compute the updated V for the movie\n",
    "        V[:, j] = np.dot(np.linalg.inv(np.dot(U_i, U_i.T) + lambda_V * np.identity(d_dims)),\n",
    "                         np.dot(R[R[:, j] > 0, j], U_i.T))\n",
    "\n",
    "    # Update the parameters dictionary with the updated U and V\n",
    "    parameters['U_result'] = U\n",
    "    parameters['V_result'] = V\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQ5in2inJApx"
   },
   "source": [
    "Now let's implement the __Log-a posteriori__:\n",
    "\n",
    "\\begin{equation}\n",
    "\\large\n",
    "L=-\\frac 1 2 \\left(\\sum_{i=1}^N\\sum_{j=1}^M(R_{ij}-U_i^TV_j)_{(i,j) \\in \\Omega_{R_{ij}}}^2+\\lambda_U\\sum_{i=1}^N\\|U_i\\|_{Fro}^2+\\lambda_V\\sum_{j=1}^M\\|V_j\\|_{Fro}^2\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5PUgHUp2MeZI"
   },
   "outputs": [],
   "source": [
    "def log_a_posteriori():\n",
    "    # Extract regularization parameters and result matrices from the 'parameters' dictionary\n",
    "    lambda_U = parameters['lambda_U']\n",
    "    lambda_V = parameters['lambda_V']\n",
    "    U_result = parameters['U_result']\n",
    "    V_result = parameters['V_result']\n",
    "    R = parameters['R']\n",
    "\n",
    "    UV = np.dot(U_result.T, V_result)\n",
    "\n",
    "    # Compute the difference between observed ratings R and UV where R is greater than 0\n",
    "    R_UV = (R[R > 0] - UV[R > 0])\n",
    "\n",
    "    # Compute and return the negative log of the a posteriori probability\n",
    "    return -0.5 * (np.sum(np.dot(R_UV, R_UV.T)) + lambda_U * np.sum(np.dot(U_result, U_result.T)) + \\\n",
    "                   lambda_V * np.sum(np.dot(V_result, V_result.T)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6R1ePeME7qSW"
   },
   "source": [
    "For the purposes of __scaling__, we need the maximum and minimum rating values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNIlELvx0M0W"
   },
   "outputs": [],
   "source": [
    "def update_max_min_ratings():\n",
    "    \"\"\"\n",
    "    Update the maximum and minimum rating values in the parameters dictionary.\n",
    "    \"\"\"\n",
    "    # Retrieve the U_result and V_result parameters\n",
    "    U = parameters['U_result']\n",
    "    V = parameters['V_result']\n",
    "\n",
    "    # Compute the dot product of U_result and V_result\n",
    "    R = U.T @ V\n",
    "\n",
    "    # Find the minimum and maximum values in R\n",
    "    min_rating = np.min(R)\n",
    "    max_rating = np.max(R)\n",
    "\n",
    "    # Store the minimum and maximum ratings in the parameters dictionary\n",
    "    parameters['min_rating'] = min_rating\n",
    "    parameters['max_rating'] = max_rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "68fmuPQrPRnU"
   },
   "source": [
    "The __predict__ function allows us to predict the rating value given the __user_id__ and the __movie_id__ parameters. The value has been scaled within the range 0-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "neTN8ejbQ5dg"
   },
   "outputs": [],
   "source": [
    "def predict(user_id, movie_id):\n",
    "    # Extract optimized matrices U and V from 'parameters' dictionary\n",
    "    U = parameters['U_result']\n",
    "    V = parameters['V_result']\n",
    "\n",
    "    user_id = int(user_id)\n",
    "    movie_id = int(movie_id)\n",
    "\n",
    "    # Compute the predicted rating for the given user and movie \n",
    "    r_ij = U[:, user_id-1].T.reshape(1, -1) @ V[:, movie_id-1].reshape(-1, 1) \n",
    "\n",
    "    max_rating = parameters['max_rating']\n",
    "    min_rating = parameters['min_rating']\n",
    "\n",
    "    # Normalize the predicted rating to be between 0 and 5 if possible, else return 0\n",
    "    return 0 if max_rating == min_rating else ((r_ij[0][0] - min_rating) / (max_rating - min_rating)) * 5.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(n_users, n_movies):\n",
    "    R = parameters['R']\n",
    "    U_result = parameters['U_result']\n",
    "    V_result = parameters['V_result']\n",
    "    \n",
    "    # Compute the predicted ratings matrix by taking the dot product of U_result and V_result\n",
    "    R_result = U_result.T @ V_result\n",
    "    \n",
    "    # Compute the Frobenius norm of the difference between actual and predicted ratings matrices, \n",
    "    # and normalize it by the square root of the total number of ratings\n",
    "    diff_norm_R = np.linalg.norm(R - R_result, 'fro')/np.sqrt(n_movies*n_users) \n",
    "    \n",
    "    return diff_norm_R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Rt2ol1j7OJ0"
   },
   "source": [
    "The __evaluate__ function will calculate the __RMSE__ of the model given a dataset (train or test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset):\n",
    "    ground_truths = []\n",
    "    predictions = []\n",
    "\n",
    "    # Iterate over each row in the dataset\n",
    "    for index, row in dataset.iterrows():    \n",
    "        # Append the actual rating to the ground_truths list\n",
    "        ground_truths.append(row.loc['rating'])\n",
    "        # Predict the rating using our model and append it to the predictions list\n",
    "        predictions.append(predict(row.loc['userID'], row.loc['movieID'])) \n",
    "\n",
    "    # Compute and return the root mean squared error (RMSE) between the ground truth and predicted ratings\n",
    "    return mean_squared_error(ground_truths, predictions, squared=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZGq6J9pDl5O"
   },
   "source": [
    "The __train__ function implements the code necessary for training the model as well as recording the __RMSE__ values on the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VYwTD_nBNO5F"
   },
   "outputs": [],
   "source": [
    "def train(train_set, test_set, n_users, n_movies, d_dims):\n",
    "    log_aps = []\n",
    "    rmse_train = []\n",
    "    rmse_test = []\n",
    "\n",
    "    update_max_min_ratings()\n",
    "    \n",
    "    # Compute and append RMSE for training and test set before training begins\n",
    "    rmse_train.append(evaluate(train_set))\n",
    "    rmse_test.append(evaluate(test_set))\n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    # The training process will continue until the absolute difference between consecutive \n",
    "    # log a posteriori values is less than 0.0001\n",
    "    while True:\n",
    "\n",
    "        if len(log_aps) > 2:\n",
    "            if np.abs(log_aps[-1] - log_aps[-2]) < 0.0001: \n",
    "                break\n",
    "        update_parameters(n_users, n_movies, d_dims)\n",
    "        log_ap = log_a_posteriori()\n",
    "        log_aps.append(log_ap)\n",
    "        \n",
    "        k += 1\n",
    "        if (k + 1) % 25 == 0: \n",
    "            update_max_min_ratings()\n",
    "            rmse_train.append(evaluate(train_set))\n",
    "            rmse_test.append(evaluate(test_set))\n",
    "            print('Log p a-posteriori at iteration', k + 1, ':', log_ap)\n",
    "\n",
    "    update_max_min_ratings()\n",
    "    \n",
    "    # Compute the normalized difference between the actual and predicted ratings\n",
    "    diff_norm_R = compare_results(n_users, n_movies)\n",
    "    \n",
    "    return log_aps, rmse_train, rmse_test, diff_norm_R \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJbozBbQPk9A"
   },
   "source": [
    "Let's train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data_dimension_experiment(d_vals, n_users, n_items, ratings_matrix):    \n",
    "    data = []\n",
    "    np.set_printoptions(precision = 6)\n",
    "\n",
    "    for i in range(len(d_vals)):\n",
    "        \n",
    "        # Initialize parameters using the current dimension and the ratings matrix\n",
    "        init_params_real_data(sigma_u/sigma, sigma_v/sigma, mu, sigma, d_vals[i], n_users, n_items, ratings_matrix) \n",
    "        \n",
    "        df_ratings = create_real_data_df(n_users, n_items) \n",
    "        train_set, test_set = split_train_test(df_ratings, train_size=0.95)\n",
    "        _, rmse_train, rmse_test, diff_R = train(train_set, test_set, n_users, n_items, d_vals[i]) \n",
    "        \n",
    "        row= [n_users, n_items, d_vals[i], diff_R, rmse_train[-1], rmse_test[-1]]\n",
    "        data.append(row)       \n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(data, group_nbr):\n",
    "    df = pd.DataFrame(data, columns = ['N', 'M', 'D', 'diff_R', 'rmse_train', 'rmse_test']) \n",
    "    df.drop(['N', 'M'], axis=1, inplace=True)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Plot 'D' against 'diff_R'\n",
    "    ax1.plot(df['D'], df['diff_R'], marker='o')\n",
    "    ax1.set_xlabel('D')\n",
    "    ax1.set_ylabel('diff_R')\n",
    "\n",
    "    # Set the title based on group number\n",
    "    if group_nbr is np.nan:\n",
    "        ax1.set_title('Variation of diff_R for varying D')\n",
    "    else:\n",
    "        ax1.set_title(f'Variation of diff_R for varying D for group {group_nbr}')\n",
    "\n",
    "    # Plot 'D' against 'rmse_train' and 'rmse_test'\n",
    "    ax2.plot(df['D'], df['rmse_train'], marker='o', label='rmse_train')\n",
    "    ax2.plot(df['D'], df['rmse_test'], marker='o', label='rmse_test')\n",
    "    ax2.set_xlabel('D')\n",
    "    ax2.set_ylabel('rmse')\n",
    "\n",
    "    # Set the title based on group number\n",
    "    if group_nbr is np.nan:\n",
    "        ax2.set_title('Variation of rmse for varying D')\n",
    "    else:\n",
    "        ax2.set_title(f'Variation of rmse for varying D for group {group_nbr}')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vals = [5, 25, 50, 100, 150, 200] \n",
    "ratings_matrix, n_users, n_items = preprocess_data(ratings_df)\n",
    "data = real_data_dimension_experiment(d_vals, n_users, n_items, ratings_matrix) \n",
    "plot_results(data, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dfs = [group_0_df, group_1_df, group_2_df, group_3_df, group_4_df]\n",
    "group_nbrs = [0, 1, 2, 3, 4]\n",
    "d_vals = [5, 10, 25, 30,40, 50, 60] \n",
    "\n",
    "for group_df, group_nbr in zip(group_dfs, group_nbrs):\n",
    "    ratings_matrix, n_users, n_items = preprocess_data(group_df)\n",
    "    data = real_data_dimension_experiment(d_vals, n_users, n_items, ratings_matrix)\n",
    "    plot_results(data, group_nbr)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PMF_Recommender_Systems.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "adaexam",
   "language": "python",
   "name": "adaexam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
