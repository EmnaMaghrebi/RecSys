{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efed0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from helpers_pmf import *\n",
    "from helpers_similarity import *\n",
    "from helpers_optimization import *\n",
    "from scipy.optimize import minimize\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d457406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0\n",
    "sigma_u = 1\n",
    "sigma_v = 1\n",
    "sigma = 0\n",
    "lambda_reg = 0.1\n",
    "parameters = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f0234d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the tensor Y:  (50, 73, 73)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0., -1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.load('data/tensor_Y.npy')\n",
    "n_users, n_items, _ = Y.shape\n",
    "print(\"Shape of the tensor Y: \", Y.shape)\n",
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "780b0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_P_BT_Luce(X, n_users, alpha=1.0): # tha larger alpha, the flatter and noisier the sigmoid is !! read abt it !!\n",
    "    # this method breaks down when n_users*n_movies is large (e.g., more than a million).\n",
    "    diff = alpha*np.subtract.outer(X, X) \n",
    "    X_diff= np.array([diff[i, :, i, :] for i in range(n_users)])\n",
    "    P = np.exp(X_diff) / (1 + np.exp(X_diff))\n",
    "    \n",
    "    return P, X_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a59a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_comparisons(P):\n",
    "    \n",
    "    Y = np.random.binomial(n=1, p=P, size=P.shape) \n",
    "    Y = np.where(Y == 0, -1, Y)\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "694754ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(x):\n",
    "    return np.maximum(0, 1 - x)**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c89b3eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_loss(U, V, Y):\n",
    "    n, m, _ = Y.shape\n",
    "    loss = 0\n",
    "    for j in range(m):\n",
    "        v = V[:,j] - V.T\n",
    "        x = np.dot(v, U)\n",
    "        loss += np.sum(hinge_loss(Y[:,j]*x.T)[:,:j])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8091a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_U(U, Y, V, lambda_reg, d_dim, n_users):\n",
    "    U = U.reshape((d_dim, n_users))\n",
    "    loss = sum_loss(U, V, Y)\n",
    "    reg = lambda_reg * np.linalg.norm(U, 'fro') ** 2 \n",
    "    \n",
    "    return loss + reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "84b1ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_V(V, Y, U, lambda_reg, d_dim, n_movies):\n",
    "    V = V.reshape((d_dim, n_movies))\n",
    "    loss = sum_loss(U, V, Y)\n",
    "    reg = lambda_reg * np.linalg.norm(V, 'fro') ** 2\n",
    "    \n",
    "    return loss + reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9487a3",
   "metadata": {},
   "source": [
    "## Alternating Minimization of U and V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022f7f6",
   "metadata": {},
   "source": [
    "Explain what we're doing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f1fc012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(Y, sigma_u, sigma_v, mu, sigma, d_dims, n_users, n_movies, lambda_reg):  \n",
    "\n",
    "    U_init = np.random.normal(mu, sigma_u, (d_dims, n_users))\n",
    "    V_init = np.random.normal(mu, sigma_v, (d_dims, n_movies))   \n",
    "   \n",
    "    #parameters['P'] = P\n",
    "    parameters['Y'] = Y\n",
    "    parameters['U_result'] = U_init\n",
    "    parameters['V_result'] = V_init\n",
    "    parameters['lambda_reg'] = lambda_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "69317c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(d_dim, n_users, n_movies):\n",
    "    U_prev = parameters['U_result']\n",
    "    V_prev = parameters['V_result']\n",
    "    Y = parameters['Y']\n",
    "\n",
    "    U_prev = U_prev.reshape((d_dim, n_users))\n",
    "    V_prev = V_prev.reshape((d_dim, n_movies))\n",
    "\n",
    "    U_result = minimize(loss_U, U_prev, args=(Y, V_prev, lambda_reg, d_dim, n_users), method='L-BFGS-B')\n",
    "    V_result = minimize(loss_V, V_prev, args=(Y, U_prev, lambda_reg, d_dim, n_movies), method='L-BFGS-B')\n",
    "    \n",
    "    U_result = U_result.x.reshape((d_dim, n_users))\n",
    "    V_result = V_result.x.reshape((d_dim, n_movies))\n",
    "    \n",
    "    parameters['U_result'] = U_result\n",
    "    parameters['V_result'] = V_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "44f4606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(d_dim, n_users, n_movies):\n",
    "    U_result = parameters['U_result']\n",
    "    V_result = parameters['V_result']\n",
    "    Y = parameters['Y']\n",
    "    lambda_reg = parameters['lambda_reg']\n",
    "\n",
    "    loss_u = loss_U(U_result, Y, V_result, lambda_reg, d_dim, n_users) /(d_dim*n_users) # normalize by n_users or d_dim*n_users ??\n",
    "    loss_v = loss_V(V_result, Y, U_result, lambda_reg, d_dim, n_movies) /(d_dim*n_movies)\n",
    "    \n",
    "    return loss_u, loss_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a54e0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orth_procrustes(X, Y, len_X):\n",
    "    R, scale = orthogonal_procrustes(X, Y)\n",
    "    rss = np.linalg.norm(X @ R - Y, 'fro')/np.sqrt(len_X)\n",
    "    \n",
    "    return rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bbb1bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(n_users):\n",
    "    Y = parameters['Y']\n",
    "    U_result = parameters['U_result']\n",
    "    V_result = parameters['V_result']\n",
    "    \n",
    "    X_result = np.matmul(U_result.T, V_result)\n",
    "    P_result, _ = generate_P_BT_Luce(X_result, n_users)\n",
    "    Y_result = pairwise_comparisons(P_result)\n",
    "    diff_norm_Y = np.linalg.norm(Y - Y_result)\n",
    "    \n",
    "    return diff_norm_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "68e46db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_minimization_U_V(Y, d_dims, n_users, n_movies):\n",
    "    initialize_parameters(Y, sigma_u, sigma_v, mu, sigma, d_dims, n_users, n_movies, lambda_reg) \n",
    "    loss_u_vals = []\n",
    "    loss_v_vals = []\n",
    "    #while True:\n",
    "    for i in range(25): # 50\n",
    "        if len(loss_u_vals) > 2:\n",
    "            if np.abs(loss_u_vals[-1] - loss_u_vals[-2]) < 0.1:\n",
    "                break\n",
    "        update_parameters(d_dims, n_users, n_movies)\n",
    "\n",
    "        loss_u, loss_v = loss(d_dims, n_users, n_movies)\n",
    "        loss_u_vals.append(loss_u)\n",
    "        loss_v_vals.append(loss_v) \n",
    "        if i % 10 == 0:\n",
    "            print(f'loss_u: {loss_u}, loss_v: {loss_v}')      \n",
    "                \n",
    "    diff_norm_Y = compare_results(n_users)\n",
    "    \n",
    "    return diff_norm_Y, loss_u_vals, loss_v_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ebd23faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(data):\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['D', 'diff_Y']) # remove N and M\n",
    "    df.drop(['N', 'M'], axis=1, inplace=True)\n",
    "\n",
    "    # plot D as a function of diff_Y\n",
    "    plt.plot(df['D'], df['diff_Y'], marker='o')\n",
    "    plt.set_xlabel('D')\n",
    "    plt.set_ylabel('diff_Y')\n",
    "    plt.set_title('Variation of diff_Y for varying D')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "93712f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 50, M: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/l6vpn95x35g0swp7xwnqndtc0000gn/T/ipykernel_64244/1314612138.py:9: DeprecationWarning: Use of `minimize` with `x0.ndim != 1` is deprecated. Currently, singleton dimensions will be removed from `x0`, but an error will be raised in SciPy 1.11.0.\n",
      "  U_result = minimize(loss_U, U_prev, args=(Y, V_prev, lambda_reg, d_dim, n_users), method='L-BFGS-B')\n",
      "/var/folders/y6/l6vpn95x35g0swp7xwnqndtc0000gn/T/ipykernel_64244/1314612138.py:10: DeprecationWarning: Use of `minimize` with `x0.ndim != 1` is deprecated. Currently, singleton dimensions will be removed from `x0`, but an error will be raised in SciPy 1.11.0.\n",
      "  V_result = minimize(loss_V, V_prev, args=(Y, U_prev, lambda_reg, d_dim, n_movies), method='L-BFGS-B')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_u: 1316.2301448361065, loss_v: 901.5137729238755\n",
      "loss_u: 1315.5359773957787, loss_v: 901.0556540250928\n",
      "loss_u: 1315.542758203248, loss_v: 901.0615622583603\n",
      "loss_u: 526.616763865735, loss_v: 360.6954461595333\n",
      "loss_u: 263.1549632076124, loss_v: 180.26060761452317\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "d_dims = [2, 5, 10]\n",
    "print(f'N: {n_users}, M: {n_items}')\n",
    "\n",
    "for i in range(len(d_dims)):\n",
    "\n",
    "    diff_Y, loss_u_vals, loss_v_vals = alt_minimization_U_V(Y, d_dims[i], n_users, n_items)\n",
    "    row= [d_dims[i], diff_Y]\n",
    "    data.append(row)\n",
    "    \n",
    "plot_results(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b7df7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig('results_optimization.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaexam",
   "language": "python",
   "name": "adaexam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
